{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_image(src_image, size=(32,32), bg_color=[79, 69, 54]): \n",
    "    org_size = src_image.shape\n",
    "    l = 0\n",
    "    t = 0\n",
    "    r = 0\n",
    "    b = 0\n",
    "    cr_l = 0\n",
    "    cr_t = 0\n",
    "    cr_r = org_size[1]\n",
    "    cr_b = org_size[0]\n",
    "    if org_size[1] < 32:\n",
    "        l = int(np.ceil((32 - org_size[1])/2))\n",
    "        r = int(np.floor((32 - org_size[1])/2))\n",
    "    elif org_size[1] > 32:\n",
    "        cr_l = int(np.ceil((org_size[1] - 32)/2))\n",
    "        cr_r = int(org_size[1] - np.floor((org_size[1] - 32)/2))\n",
    "    if org_size[0] > 32:\n",
    "        cr_t = int(np.ceil((org_size[0] - 32)/2))\n",
    "        cr_b = int(org_size[0] - np.floor((org_size[0] - 32)/2))\n",
    "    elif org_size[0] < 32:\n",
    "        t = int(np.ceil((32 - org_size[0])/2))\n",
    "        b = int(np.floor((32 - org_size[0])/2))\n",
    "\n",
    "    src_image = src_image[cr_t:cr_b, cr_l:cr_r]\n",
    "    new_image = cv2.copyMakeBorder(src_image, t,b,l,r, borderType=cv2.BORDER_CONSTANT, value=bg_color)\n",
    "  \n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"0\", \"1\"]\n",
    "\n",
    "\n",
    "train_folder = 'train_images'\n",
    "\n",
    "\n",
    "for root, subfolders, files in os.walk(train_folder):\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(root, file_name)\n",
    "        image = cv2.imread(file_path)\n",
    "        resized_image = resize_image(image)\n",
    "        cv2.imwrite(file_path, resized_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_path):\n",
    "\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=transformation\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        full_dataset,\n",
    "        batch_size=770,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return train_loader\n",
    "\n",
    "train_folder = 'train_images'\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "train_loader = load_dataset(train_folder)\n",
    "batch_size = train_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=600, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "       \n",
    "        self.fc1 = nn.Linear(5 * 5 * 24, out_features=120)\n",
    "\n",
    "        self.fc2 = nn.Linear(120, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        x = F.relu(self.pool(self.conv1(x))) \n",
    "        x = F.relu(self.pool(self.conv2(x)))  \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "    \n",
    "device = \"cpu\"\n",
    "model = Net(num_classes=len(classes)).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_criteria(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('\\tTraining batch {} Loss: {:.6f}'.format(batch_idx + 1, loss.item()))\n",
    "\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Epoch: 1\n",
      "\tTraining batch 1 Loss: 0.634321\n",
      "Training set: Average loss: 0.634321\n",
      "Epoch: 2\n",
      "\tTraining batch 1 Loss: 0.503531\n",
      "Training set: Average loss: 0.503531\n",
      "Epoch: 3\n",
      "\tTraining batch 1 Loss: 0.488922\n",
      "Training set: Average loss: 0.488922\n",
      "Epoch: 4\n",
      "\tTraining batch 1 Loss: 0.463278\n",
      "Training set: Average loss: 0.463278\n",
      "Epoch: 5\n",
      "\tTraining batch 1 Loss: 0.465249\n",
      "Training set: Average loss: 0.465249\n",
      "Epoch: 6\n",
      "\tTraining batch 1 Loss: 0.458334\n",
      "Training set: Average loss: 0.458334\n",
      "Epoch: 7\n",
      "\tTraining batch 1 Loss: 0.424054\n",
      "Training set: Average loss: 0.424054\n",
      "Epoch: 8\n",
      "\tTraining batch 1 Loss: 0.427353\n",
      "Training set: Average loss: 0.427353\n",
      "Epoch: 9\n",
      "\tTraining batch 1 Loss: 0.381081\n",
      "Training set: Average loss: 0.381081\n",
      "Epoch: 10\n",
      "\tTraining batch 1 Loss: 0.388016\n",
      "Training set: Average loss: 0.388016\n",
      "Epoch: 11\n",
      "\tTraining batch 1 Loss: 0.337151\n",
      "Training set: Average loss: 0.337151\n",
      "Epoch: 12\n",
      "\tTraining batch 1 Loss: 0.319826\n",
      "Training set: Average loss: 0.319826\n",
      "Epoch: 13\n",
      "\tTraining batch 1 Loss: 0.330791\n",
      "Training set: Average loss: 0.330791\n",
      "0.3307909667491913 0.3307909667491913\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "loss_criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "epoch_nums = [0]\n",
    "training_loss = [999]\n",
    "epochs = 50\n",
    "print('Training on', device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss) \n",
    "        if epoch > 10 and training_loss[-2] - train_loss < 0.01:\n",
    "                print(training_loss[-1], train_loss)\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'basket_cl2.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
